---
layout: post
title: MPI チュートリアル イントロダクション
author: Wes Kendall
categories: Beginner MPI
tags:
redirect_from: '/mpi-introduction/'
---

もはや並列計算はパソコン、スマートフォン、その他の技術と同じように人々の生活の一部となっています。これはこのWebサイトにアクセスするような方はご存じのことでしょう。並列プログラミングを学ぶというのは、学校でで学習している方・仕事のために学びたい方・趣味として学びたい方、どんな方にも今後にも活用できる非常に価値のある選択といえます。私の意見ですが、メッセージ パッシング インターフェイス(MPI)の学習は、並列プログラミングの知識を広げる正しい道です。MPI は他の多くの並列プログラミングライブラリ(Hadoopなど)よりも低レベルですが、並列プログラミングに関する知識を構築するためのとてもよい基礎となります。

どうして私が、このMPIに関するリソースを作成したかを説明します。私は、大学院時代に MPIをよく使用していました。幸いにもアルゴンヌ国立研究所([Argonne National Laboratory](http://www.anl.gov))でのインターンシップ中にMPIコミュニティの重要人物と出会うことができ、博士時代には大規模なスーパーコンピューティング資源とMPIを用いたクレイジーな研究に取り組めました。しかし、このような人脈とリソースの中にあってもMPIの学習は依然として難しいと未だに思っています。

MPI学習が難しいと感じたのには3つの理由があります。まず、MPI学習のオンラインリソースは時代遅れか不十分な内容でした。次に、自分でクラスタを簡単に利用・構築する方法が記載されたリソースを見つけるのは困難でした。最後に、大学院時代の最も安価なMPIの本は60ドルもしました。これは大学院生にとっては高額です。現代おける並列プログラミングの重要性を考えると、並列アプリケーションのための基本的なインターフェイスの1つに関する情報に人々がアクセスがとても重要だと考えています。

私はMPIの専門家ではありません。ですが、大学院時代に学んだMPIに関するすべての情報を、*皆さん自身の*クラスタで実行できるサンプルコードを含む簡単なチュートリアル形式で広めることは有益だと考えています。このWebサイトの情報が皆さんのキャリア、研究、または人生にとって貴重なツールとなることを願っています。並列プログラミングは現在だけでなく*未来でもある*からです。

## MPIの歴史(概略): A brief history of MPI
1990年代以前、現在のMPIのようなスタイルで並列計算プログラムを書くことはできませんでした。異なるコンピュータアーキテクチャに対するプログラミングと言うのは困難で退屈を極めました。いくつかのライブラリが生まれましたがそれらが標準となることはありませんでした。

その時代の並列アプリケーションはほとんどが科学や研究領域のためのものでした。この中で、最も一般的に採用されたライブラリのモデルがメッセージ・パッシング・モデルです。このモデルを利用するアプリケーションは、あるタスクを実行するためにプロセス間でメッセージを受け渡しを行います。このモデルは並列アプリケーションで非常にうまく機能します。マネージャー・プロセスはワーカー・プロセスに操作命令を含んだメッセージを渡して、ワーカー・プロセスに操作を割り当てることができます。例えばマージソートを並列処理するとします。各プロセス上はローカルのデータをソートし、そのローカルのソート済みのデータを全体でマージするために、隣接したプロセスに結果を渡します。このように多くの並列アプリケーションはメッセージパッシングモデルで表現できます。

この時代に登場したライブラリはメッセージパッシングモデルであり各ライブラリ間の機能の違い少なかったため、1992年のSupercomputingカンファレンスにおいて各ライブラリの作者が集ってメッセージパッシングの実行標準インターフェースであるMessage Passing Interfaceを定義しました。これを契機にプログラマはすべての主要な並列アーキテクチャに移植可能な並列アプリケーションを書くことができるようになりました。また、現在も一般的に使われているライブラリの使われている機能やモデルもこの時から出現しました。

そして1994年までに完全なインターフェースと標準が定義されこれはMPI-1と呼ばれています。とはいえ、MPIは特定の実装でなくインターフェイスの定義です。各々のアーキテクチャに対応したインタフェースを実装を作成するのは開発者に委ねられていました。しかし、幸いにもMPIの完全な実装が利用できるようになるまで、1年程度しかかかりませんでした。この最初の実装が作られた後、MPIは広く採用され今でもメッセージパッシング・アプリケーションを書くための*事実上の（デファクトの）*手法であり続けています。

![An accurate representation of the first MPI programmers.](../90s_nerd.jpg)
*最初のMPIプログラマ*

## MPIメッセージパッシングモデルの設計： MPI's design for the message passing model
並列プログラミングのメッセージパッシングモデルであるMPIの設計における、いくつかの古典的な概念について説明します。まずは、`コミュニケータ`という概念です。コミュニケータは互いに通信可能なプロセスのグループです。このプロセスグループでは、各プロセスに固有の`ランク`が割り当てられており、そのランクで互いを区別して明示的に通信を行います。

通信の基本はプロセス間の送受信操作です。送信側のプロセスはランクとメッセージを識別するためのユニークな`タグ`を用いて別のプロセスにメッセージを送信します。受信側のプロセスは指定されたタグを持つメッセージの受信してデータを処理します。このような1つの送信者と受信者が関わる通信を`ポイント・ツー・ポイント通信`と呼びます。

プロセスが他の全プロセスと通信したいことがあります。例えば、マネージャー・プロセスがワーカー・プロセスすべてにデータをブロードキャストすることを考えましょう。１つ１つの送受信を行うコードを書くのは面倒ですし、最適な方法でネットワークを利用するのも難しいです。MPIはこのような全プロセスを含む様々な種類の`集団通信(collective communication)`を扱うことができます。

ポイント・ツー・ポイント通信と集団通信を組み合わせることで、非常に複雑な並列プログラムが作成できます。これらの機能は非常にパワフルな高度なメカニズムを持ちます。この説明は後のレッスンまで取っておくことにして、今は[MPIをシングルマシンにインストールする]({{ site.baseurl }}/tutorials/installing-mpich2/)か、[Amazon EC2 MPIクラスタを起動する]({{ site.baseurl }}/tutorials/launching-an-amazon-ec2-mpi-cluster/)に取り組んでください。既にMPIがインストールされているなら、それは素晴らしい！[MPI Hello World]({{ site.baseurl }}/tutorials/mpi-hello-world)に進んでください。